{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib as plt\n",
    "import pickle\n",
    "import statistics\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normalize_features(dbpath):\n",
    "    newdf = pd.DataFrame(columns=[\"class\", \"path\", \"V\", \"S\", \"c\", \"D\", \"R\", \"E\", \"C\", \"A3\", \"D1\", \"D2\", \"D3\", \"D4\"]) \n",
    "    list_values_1 = []\n",
    "    list_values_2 = []\n",
    "    list_values_3 = []\n",
    "    list_values_4 = []\n",
    "    list_values_5 = []\n",
    "    list_values_6 = []\n",
    "    list_values_7 = []\n",
    "\n",
    "    for class_folder in os.listdir(dbpath):\n",
    "        class_path = os.path.join(dbpath, class_folder)\n",
    "        for obj_file_path in glob.glob(os.path.join(class_path, '*')):\n",
    "            data = []\n",
    "            data.append(np.load(obj_file_path, allow_pickle=True))\n",
    "            data = data[0]\n",
    "\n",
    "            # Create list for every feature of all objects\n",
    "            list_values_1.append(data[0])\n",
    "            list_values_2.append(data[1])\n",
    "            list_values_3.append(data[2])\n",
    "            list_values_4.append(data[3])\n",
    "            list_values_5.append(data[4])\n",
    "            list_values_6.append(data[5])\n",
    "            list_values_7.append(data[6])\n",
    "    #compute average for every feature list\n",
    "    list_values_1_avr = sum(list_values_1)/len(list_values_1)\n",
    "    list_values_2_avr = sum(list_values_2)/len(list_values_2)\n",
    "    list_values_3_avr = sum(list_values_3)/len(list_values_3)\n",
    "    list_values_4_avr = sum(list_values_4)/len(list_values_4)\n",
    "    list_values_5_avr = sum(list_values_5)/len(list_values_5)\n",
    "    list_values_6_avr = sum(list_values_6)/len(list_values_6)\n",
    "    list_values_7_avr = sum(list_values_7)/len(list_values_7)\n",
    "    #compute standart deviation for every feature list\n",
    "    list_values_1_std = statistics.stdev(list_values_1)\n",
    "    list_values_2_std = statistics.stdev(list_values_2)\n",
    "    list_values_3_std = statistics.stdev(list_values_3)\n",
    "    list_values_4_std = statistics.stdev(list_values_4)\n",
    "    list_values_5_std = statistics.stdev(list_values_5)\n",
    "    list_values_6_std = statistics.stdev(list_values_6)\n",
    "    list_values_7_std = statistics.stdev(list_values_7)\n",
    "\n",
    "    #standardization for every feature of every object in the database\n",
    "    for class_folder in os.listdir(dbpath):\n",
    "        class_path = os.path.join(dbpath, class_folder)\n",
    "        for obj_file_path in glob.glob(os.path.join(class_path, '*')):\n",
    "                data = np.load(obj_file_path, allow_pickle=True)\n",
    "                data1 = (data[0]-list_values_1_avr)/list_values_1_std\n",
    "                data2 = (data[1]-list_values_2_avr)/list_values_2_std\n",
    "                data3 = (data[2]-list_values_3_avr)/list_values_3_std\n",
    "                data4 = (data[3]-list_values_4_avr)/list_values_4_std\n",
    "                data5 = (data[4]-list_values_5_avr)/list_values_5_std\n",
    "                data6 = (data[5]-list_values_6_avr)/list_values_6_std\n",
    "                data7 = (data[6]-list_values_7_avr)/list_values_7_std\n",
    "\n",
    "                #add normalized feature vector to new data frame\n",
    "                new_row = {1:[class_folder, obj_file_path, data1, data2, data3, data4, data5, data6, data7, data[7], data[8], data[9], data[10], data[11]]}\n",
    "                df_new_row = pd.DataFrame.from_dict(new_row, \n",
    "                       orient='index', \n",
    "                       columns=[\"class\", \"path\", \"V\", \"S\", \"c\", \"D\", \"R\", \"E\", \"C\", \"A3\", \"D1\", \"D2\", \"D3\", \"D4\"])\n",
    "                newdf = pd.concat([newdf, df_new_row])\n",
    "    \n",
    "    print(\"Normalization completed!\")\n",
    "    return newdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Failed to interpret file './features/Jet\\\\m1193' as a pickle",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\bas\\anaconda3\\envs\\mrproject\\lib\\site-packages\\numpy\\lib\\npyio.py:441\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39;49mload(fid, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mpickle_kwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mEOFError\u001b[0m: Ran out of input",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\bas\\Desktop\\multimedia retrieval project\\Multimedia-Retrieval\\feature_normalization.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dbpath \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./features/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m normalized_features_df \u001b[39m=\u001b[39m Normalize_features(dbpath)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m normalized_features_df\n",
      "\u001b[1;32mc:\\Users\\bas\\Desktop\\multimedia retrieval project\\Multimedia-Retrieval\\feature_normalization.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m obj_file_path \u001b[39min\u001b[39;00m glob\u001b[39m.\u001b[39mglob(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(class_path, \u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     data \u001b[39m=\u001b[39m []\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     data\u001b[39m.\u001b[39mappend(np\u001b[39m.\u001b[39;49mload(obj_file_path, allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     data \u001b[39m=\u001b[39m data[\u001b[39m0\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/bas/Desktop/multimedia%20retrieval%20project/Multimedia-Retrieval/feature_normalization.ipynb#W2sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Create list for every feature of all objects\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\bas\\anaconda3\\envs\\mrproject\\lib\\site-packages\\numpy\\lib\\npyio.py:443\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[39mreturn\u001b[39;00m pickle\u001b[39m.\u001b[39mload(fid, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpickle_kwargs)\n\u001b[0;32m    442\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 443\u001b[0m     \u001b[39mraise\u001b[39;00m pickle\u001b[39m.\u001b[39mUnpicklingError(\n\u001b[0;32m    444\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to interpret file \u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m!r}\u001b[39;00m\u001b[39m as a pickle\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: Failed to interpret file './features/Jet\\\\m1193' as a pickle"
     ]
    }
   ],
   "source": [
    "dbpath = r\"./features/\"\n",
    "\n",
    "normalized_features_df = Normalize_features(dbpath)\n",
    "normalized_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features_df\n",
    "normalized_features_df.to_pickle(\"normalized_features_final.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
