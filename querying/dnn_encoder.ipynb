{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pymeshlab as pml\n",
    "import time\n",
    "import matplotlib as plt\n",
    "import sys\n",
    "sys.path.append('../preprocessing')\n",
    "from viz import viz_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_pickle(\"../querying/normalized_features_final.pkl\")\n",
    "k = 10\n",
    "npdata = df[df.columns[2:9]].to_numpy()\n",
    "for col in df.columns[9:]:\n",
    "    npcol = df[col].to_numpy()\n",
    "    npdata = np.hstack((npdata,np.array([a for a in npcol])))\n",
    "labels = df[\"class\"].to_numpy()\n",
    "\n",
    "\n",
    "features_total = npdata\n",
    "paths = (df[\"path\"].str.replace(\"./features\",\"../resampledPML\") + \".obj\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2475, 507)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "52/52 [==============================] - 4s 27ms/step - loss: 3.8402 - accuracy: 0.1091 - val_loss: 3.4124 - val_accuracy: 0.1371\n",
      "Epoch 2/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 3.1850 - accuracy: 0.2004 - val_loss: 2.9398 - val_accuracy: 0.2016\n",
      "Epoch 3/60\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 2.8418 - accuracy: 0.2440 - val_loss: 2.7255 - val_accuracy: 0.2702\n",
      "Epoch 4/60\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 2.6389 - accuracy: 0.2869 - val_loss: 2.5518 - val_accuracy: 0.2984\n",
      "Epoch 5/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 2.4425 - accuracy: 0.3196 - val_loss: 2.3883 - val_accuracy: 0.3226\n",
      "Epoch 6/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 2.3159 - accuracy: 0.3499 - val_loss: 2.3227 - val_accuracy: 0.3347\n",
      "Epoch 7/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 2.2089 - accuracy: 0.3838 - val_loss: 2.2002 - val_accuracy: 0.3911\n",
      "Epoch 8/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 2.1237 - accuracy: 0.3838 - val_loss: 2.1038 - val_accuracy: 0.4194\n",
      "Epoch 9/60\n",
      "52/52 [==============================] - 0s 10ms/step - loss: 2.0618 - accuracy: 0.4109 - val_loss: 2.0343 - val_accuracy: 0.4234\n",
      "Epoch 10/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.9907 - accuracy: 0.4259 - val_loss: 1.9339 - val_accuracy: 0.4113\n",
      "Epoch 11/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.9337 - accuracy: 0.4368 - val_loss: 1.8658 - val_accuracy: 0.4234\n",
      "Epoch 12/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.8874 - accuracy: 0.4493 - val_loss: 1.8245 - val_accuracy: 0.4476\n",
      "Epoch 13/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.8227 - accuracy: 0.4731 - val_loss: 1.7399 - val_accuracy: 0.5000\n",
      "Epoch 14/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.7731 - accuracy: 0.4885 - val_loss: 1.7384 - val_accuracy: 0.4516\n",
      "Epoch 15/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.7349 - accuracy: 0.4820 - val_loss: 1.7554 - val_accuracy: 0.4516\n",
      "Epoch 16/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.6955 - accuracy: 0.4897 - val_loss: 1.6652 - val_accuracy: 0.4960\n",
      "Epoch 17/60\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.6565 - accuracy: 0.5075 - val_loss: 1.5857 - val_accuracy: 0.5242\n",
      "Epoch 18/60\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 1.6153 - accuracy: 0.5127 - val_loss: 1.5347 - val_accuracy: 0.5565\n",
      "Epoch 19/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.5657 - accuracy: 0.5301 - val_loss: 1.4602 - val_accuracy: 0.5524\n",
      "Epoch 20/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.5392 - accuracy: 0.5398 - val_loss: 1.4931 - val_accuracy: 0.5363\n",
      "Epoch 21/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.4924 - accuracy: 0.5434 - val_loss: 1.3848 - val_accuracy: 0.5605\n",
      "Epoch 22/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.4595 - accuracy: 0.5620 - val_loss: 1.3487 - val_accuracy: 0.5927\n",
      "Epoch 23/60\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.4397 - accuracy: 0.5588 - val_loss: 1.3434 - val_accuracy: 0.5968\n",
      "Epoch 24/60\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 1.3831 - accuracy: 0.5834 - val_loss: 1.2613 - val_accuracy: 0.6331\n",
      "Epoch 25/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 1.3559 - accuracy: 0.5895 - val_loss: 1.2544 - val_accuracy: 0.6492\n",
      "Epoch 26/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.3382 - accuracy: 0.5887 - val_loss: 1.2356 - val_accuracy: 0.6371\n",
      "Epoch 27/60\n",
      "52/52 [==============================] - 1s 14ms/step - loss: 1.2822 - accuracy: 0.6121 - val_loss: 1.2222 - val_accuracy: 0.6250\n",
      "Epoch 28/60\n",
      "52/52 [==============================] - 1s 16ms/step - loss: 1.2728 - accuracy: 0.6117 - val_loss: 1.2082 - val_accuracy: 0.6290\n",
      "Epoch 29/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.2389 - accuracy: 0.6251 - val_loss: 1.1423 - val_accuracy: 0.6452\n",
      "Epoch 30/60\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 1.2108 - accuracy: 0.6307 - val_loss: 1.1613 - val_accuracy: 0.6210\n",
      "Epoch 31/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.1690 - accuracy: 0.6424 - val_loss: 1.0519 - val_accuracy: 0.6774\n",
      "Epoch 32/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.1421 - accuracy: 0.6481 - val_loss: 1.0570 - val_accuracy: 0.6815\n",
      "Epoch 33/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.1385 - accuracy: 0.6505 - val_loss: 1.0382 - val_accuracy: 0.6774\n",
      "Epoch 34/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.0920 - accuracy: 0.6545 - val_loss: 1.0197 - val_accuracy: 0.6815\n",
      "Epoch 35/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.0645 - accuracy: 0.6719 - val_loss: 0.9598 - val_accuracy: 0.7137\n",
      "Epoch 36/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 1.0329 - accuracy: 0.6715 - val_loss: 0.9857 - val_accuracy: 0.6774\n",
      "Epoch 37/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 1.0213 - accuracy: 0.6844 - val_loss: 0.9889 - val_accuracy: 0.6935\n",
      "Epoch 38/60\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.9839 - accuracy: 0.6905 - val_loss: 0.9150 - val_accuracy: 0.6935\n",
      "Epoch 39/60\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.9605 - accuracy: 0.6982 - val_loss: 0.9153 - val_accuracy: 0.6976\n",
      "Epoch 40/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.9465 - accuracy: 0.7022 - val_loss: 0.8616 - val_accuracy: 0.7137\n",
      "Epoch 41/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.8918 - accuracy: 0.7184 - val_loss: 0.8141 - val_accuracy: 0.7258\n",
      "Epoch 42/60\n",
      "52/52 [==============================] - 1s 13ms/step - loss: 0.8836 - accuracy: 0.7184 - val_loss: 0.8218 - val_accuracy: 0.7339\n",
      "Epoch 43/60\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 0.8483 - accuracy: 0.7451 - val_loss: 0.7736 - val_accuracy: 0.7540\n",
      "Epoch 44/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.8385 - accuracy: 0.7406 - val_loss: 0.7720 - val_accuracy: 0.7460\n",
      "Epoch 45/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.8467 - accuracy: 0.7386 - val_loss: 0.8103 - val_accuracy: 0.7339\n",
      "Epoch 46/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.8313 - accuracy: 0.7309 - val_loss: 0.8553 - val_accuracy: 0.7258\n",
      "Epoch 47/60\n",
      "52/52 [==============================] - 0s 9ms/step - loss: 0.8001 - accuracy: 0.7539 - val_loss: 0.6832 - val_accuracy: 0.7903\n",
      "Epoch 48/60\n",
      "52/52 [==============================] - 1s 12ms/step - loss: 0.7417 - accuracy: 0.7673 - val_loss: 0.6552 - val_accuracy: 0.7742\n",
      "Epoch 49/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.7326 - accuracy: 0.7653 - val_loss: 0.6775 - val_accuracy: 0.7742\n",
      "Epoch 50/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.7139 - accuracy: 0.7689 - val_loss: 0.6207 - val_accuracy: 0.8226\n",
      "Epoch 51/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.7237 - accuracy: 0.7745 - val_loss: 0.6328 - val_accuracy: 0.7984\n",
      "Epoch 52/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6657 - accuracy: 0.7887 - val_loss: 0.6799 - val_accuracy: 0.7419\n",
      "Epoch 53/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6557 - accuracy: 0.7822 - val_loss: 0.5416 - val_accuracy: 0.8266\n",
      "Epoch 54/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6356 - accuracy: 0.8057 - val_loss: 0.5244 - val_accuracy: 0.8589\n",
      "Epoch 55/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.6353 - accuracy: 0.7992 - val_loss: 0.5950 - val_accuracy: 0.8065\n",
      "Epoch 56/60\n",
      "52/52 [==============================] - 1s 11ms/step - loss: 0.5882 - accuracy: 0.8089 - val_loss: 0.6035 - val_accuracy: 0.7903\n",
      "Epoch 57/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5873 - accuracy: 0.8117 - val_loss: 0.4749 - val_accuracy: 0.8669\n",
      "Epoch 58/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5787 - accuracy: 0.8121 - val_loss: 0.4741 - val_accuracy: 0.8468\n",
      "Epoch 59/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5447 - accuracy: 0.8238 - val_loss: 0.4992 - val_accuracy: 0.8508\n",
      "Epoch 60/60\n",
      "52/52 [==============================] - 0s 8ms/step - loss: 0.5326 - accuracy: 0.8319 - val_loss: 0.4277 - val_accuracy: 0.8871\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Assuming 'labels' is your string label array\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Now, you can one-hot encode the integer labels\n",
    "labels_one_hot = to_categorical(labels_encoded)\n",
    "\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_normalized = scaler.fit_transform(npdata)  # Step 1: Standardization\n",
    "# scalar_X_normalized = scaler.fit_transform(scalar_features)\n",
    "\n",
    "# Split the dataset into train, test, and validation sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(npdata, labels_one_hot, test_size=0.2,  random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5,  random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(scalar_features, labels_one_hot, test_size=0.2, random_state=42)\n",
    "# X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "indices = np.arange(len(npdata))\n",
    "\n",
    "# Use train_test_split with 'indices' to split your data while maintaining index correspondence\n",
    "indices_train, indices_test = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "indices_test, indices_val = train_test_split(indices_test, test_size=0.5, random_state=42)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "X_train.shape[1]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(y_train.shape[1], activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) i used by mistake binary_crossentropy\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "np.argmax(X_train)\n",
    "history = model.fit(npdata, labels_one_hot, epochs=60, batch_size=48, validation_data=(X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shufflenpdata = np.append(np.append(X_test,X_val),X_train).reshape(-1,507)\n",
    "# shufflelabel = np.append(np.append(y_test,y_val),y_train).reshape(-1,69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 8ms/step - loss: 0.4434 - accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4434220790863037, 0.8663967847824097]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "totalpreds = model.predict(npdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest Labels: ['AircraftBuoyant', 'Rocket', 'Rocket', 'Rocket', 'Rocket', 'Rocket', 'Rocket', 'Rocket', 'Rocket', 'Rocket']\n"
     ]
    }
   ],
   "source": [
    "query_object = totalpreds[10]\n",
    "# Calculate distances using Euclidean distance as an example\n",
    "distances = np.linalg.norm(totalpreds - query_object, axis=1)\n",
    "\n",
    "# Combine distances and labels into a list of tuples\n",
    "objects_with_distances = list(zip(distances, totalpreds, labels))\n",
    "\n",
    "# Sort the objects based on distances\n",
    "objects_with_distances.sort(key=lambda x: x[0])\n",
    "\n",
    "# Get the 5 closest objects and their labels\n",
    "closest_objects = objects_with_distances[:10]\n",
    "\n",
    "# Extract the labels from the closest objects\n",
    "closest_labels = [obj[2] for obj in closest_objects]\n",
    "\n",
    "print(\"Closest Labels:\", closest_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Each Query Object: [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.4, 0.9, 1.0, 1.0, 0.8, 0.8, 0.1, 1.0, 0.3, 1.0, 0.9, 0.0, 1.0, 0.9, 1.0, 0.9, 1.0, 1.0, 0.9, 0.8, 0.9, 0.9, 0.5, 0.8, 1.0, 1.0, 1.0, 1.0, 0.8, 1.0, 1.0, 1.0, 0.8, 0.9, 0.8, 1.0, 0.0, 0.9, 1.0, 0.9, 1.0, 1.0, 1.0, 0.2, 0.9, 0.9, 0.9, 0.8, 0.9, 0.9, 0.0, 0.2, 0.9, 0.4, 0.9, 0.9, 0.8, 0.9, 0.8, 0.9, 0.9, 0.9, 0.9, 0.5, 0.6, 0.9, 0.7, 0.0, 0.8, 0.8, 0.9, 1.0, 0.9, 0.8, 0.8, 0.8, 0.9, 1.0]\n",
      "Overall Accuracy: 0.8420000000000001\n"
     ]
    }
   ],
   "source": [
    "query_objects = totalpreds[100:200]\n",
    "top_k = 10\n",
    "accuracies = []\n",
    "\n",
    "# Loop over all query objects\n",
    "for query_object in query_objects:\n",
    "    # Calculate distances using Euclidean distance as an example\n",
    "    distances = np.linalg.norm(totalpreds - query_object, axis=1)\n",
    "\n",
    "    # Combine distances and labels into a list of tuples\n",
    "    objects_with_distances = list(zip(distances, totalpreds, labels))\n",
    "\n",
    "    # Sort the objects based on distances\n",
    "    objects_with_distances.sort(key=lambda x: x[0])\n",
    "\n",
    "    # Get the 10 closest objects\n",
    "    closest_objects = objects_with_distances[1:top_k+1]\n",
    "    true_label = objects_with_distances[0][2]\n",
    "    # Extract the labels from the closest objects\n",
    "    closest_labels = [obj[2] for obj in closest_objects]\n",
    "\n",
    "    # Count how many of the closest objects have the same label as the query object\n",
    "    same_label_count = closest_labels.count(true_label)\n",
    "\n",
    "    # Calculate the accuracy for this query object\n",
    "    accuracy = same_label_count / top_k  # Since we are considering the top 10 closest objects\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = np.mean(accuracies)\n",
    "\n",
    "print(\"Accuracy for Each Query Object:\", accuracies)\n",
    "print(\"Overall Accuracy:\", overall_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mrproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
